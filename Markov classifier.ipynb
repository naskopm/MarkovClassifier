{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dda35c08-1f0e-452d-9ce8-6ab558ef37cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "import markovify\n",
    "import random\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import string\n",
    "from scipy.stats import entropy\n",
    "from time import time\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1151dbda-80b2-4fd9-afb8-e9918b53d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load passwords that are longer than 8 characters, because most of the time nowadays you can't make a password that is shorter than 8 characters\n",
    "counter = 0\n",
    "trainingPass = set()\n",
    "\n",
    "\n",
    "with open(r\"C:\\Users\\1\\Downloads\\rockyou.txt\", 'r', encoding='latin1') as file:\n",
    "    for line in file:\n",
    "        counter +=1\n",
    "        stripped_line = line.strip()\n",
    "        if len(trainingPass) > 399999:\n",
    "            break\n",
    "        if len(stripped_line) > 7 and counter > 1740247:\n",
    "            trainingPass.add(stripped_line)\n",
    "            counter += 1\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17ff3252-7e76-4788-9001-01825adb98a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingPass = set(trainingPass)\n",
    "len(trainingPass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "617db4c2-07ba-40d8-9125-2efd597764b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingPass = [str(password) for password in trainingPass]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c2a435f-b45e-4fb6-a19b-c3730431eb59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def compute_custom_features(passwords):\n",
    "    print(f\"Input passwords shape: {passwords.shape}\")\n",
    "\n",
    "    features = []\n",
    "    for password in passwords.flatten():\n",
    "        char_counts = np.array([password.count(c) for c in set(password)])\n",
    "        entropy_val = entropy(char_counts) if len(char_counts) > 1 else 0\n",
    "        length = len(password)\n",
    "        lowercase_ratio = sum(1 for c in password if c.islower()) / length\n",
    "        uppercase_ratio = sum(1 for c in password if c.isupper()) / length\n",
    "        digit_ratio = sum(1 for c in password if c.isdigit()) / length\n",
    "        symbol_ratio = sum(1 for c in password if not c.isalnum()) / length\n",
    "        features.append([entropy_val, lowercase_ratio, uppercase_ratio, digit_ratio, symbol_ratio])\n",
    "    \n",
    "    features = np.array(features)\n",
    "    print(f\"Features shape: {features.shape}\")\n",
    "    \n",
    "    # Convert the dense numeric features to a sparse format\n",
    "    return csr_matrix(features)  # Return sparse matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(r\"E:\\Nasko\\PasswordGenerator\\rockyou-xato.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "       # Join the passwords with spaces to make the model understand transitions between them\n",
    "    text = \" \".join([line.strip() for line in f.readlines() if len(line.strip()) > 7])\n",
    "    \n",
    "    model = markovify.Text(text, state_size=2)\n",
    "    bigrams = list(model.chain.model.keys())\n",
    "# Function to generate Markov-based passwords and convert to sparse matrix\n",
    "def generate_markov_password(min_length=8, max_length=16):\n",
    "    \"\"\"\n",
    "    Generate a single password using a Markov model, starting from random n-grams.\n",
    "    \n",
    "    Args:\n",
    "        min_length (int): Minimum length of the generated password.\n",
    "        max_length (int): Maximum length of the generated password.\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated password.\n",
    "    \"\"\"\n",
    "    # Train a Markov model (only once)\n",
    "   \n",
    "    \n",
    "\n",
    "    # Choose a random bigram from the model's keys to start\n",
    "    bigram = random.choice(bigrams)\n",
    "    password = ''.join(bigram)  # Initialize with the bigram\n",
    "    \n",
    "    # Generate a random password length between min_length and max_length\n",
    "    pass_length = random.randint(min_length, max_length)\n",
    "    \n",
    "    while len(password) < pass_length:\n",
    "        state = tuple(password[-2:])  # Last two characters as the new state\n",
    "        next_char_options = model.chain.model.get(state)\n",
    "        \n",
    "        if next_char_options:\n",
    "            # Select the most frequent next character\n",
    "            next_char = max(next_char_options, key=next_char_options.get)\n",
    "            password += next_char[-1]  # Append only the last character\n",
    "        else:\n",
    "            # If we hit a dead-end, restart from a new random bigram\n",
    "            bigram = random.choice(list(model.chain.model.keys()))\n",
    "            password += ''.join(bigram)[:2]  # Append part of new bigram as fallback\n",
    "\n",
    "    return password[:pass_length]\n",
    "# Function to compute entropy and character ratios for custom features\n",
    "# ColumnTransformer setup\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "287784b9-df71-4944-a665-c4eee6e97a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingPass = set(trainingPass)\n",
    "len(trainingPass)\n",
    "labels = []\n",
    "for i in range(len(trainingPass)):\n",
    "    labels.append(1)\n",
    "while len(trainingPass) < 200000:\n",
    "    trainingPass.add(generate_markov_password())\n",
    "for i in range(100000):\n",
    "    labels.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc0f8fd1-3f53-47ce-b779-d9c773abfea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "200000\n"
     ]
    }
   ],
   "source": [
    "print(len(trainingPass))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65149cbd-6e29-4b32-aac9-2fd584c8ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(trainingPass) < 300000:\n",
    "    trainingPass.add(generate_markov_password())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efd54c9b-e7fa-4342-b397-fb035f282fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingPass = list(trainingPass)\n",
    "testingData = trainingPass[-100000:]\n",
    "testingData = list(testingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cec41d7c-028e-46fc-8f95-ce86319f30f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = set()\n",
    "with open(r\"C:\\Users\\1\\Downloads\\hashmob.net.medium.found.txt\", encoding= \"utf-8\") as f:\n",
    "    for i in f:\n",
    "        if len(i) > 7:\n",
    "            wordlist.add(f)\n",
    "wordlist = list(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a53e7d6-f0a5-4f84-b742-35eca4c06871",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainingPass = np.array(trainingPass).reshape(-1,1)\n",
    "testingData  = np.array(testingData).reshape(-1,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a621f7bc-fa56-47fb-8f33-0119225b863b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n",
      "200000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "print(len(trainingPass))\n",
    "print(len(labels))\n",
    "print(len(testingData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01271942-fc24-419a-a2d0-1263f2a6d997",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingPass = trainingPass[:-100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cde6f622-23e5-4c3f-a3bd-87eb883df1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainingPass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7577ae31-85ab-4c07-90c1-68398a02bee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dense_features(passwords):\n",
    "    features = []\n",
    "    for password in passwords:\n",
    "        entropy_val = entropy(char_counts) if len(char_counts) > 1 else 0\n",
    "        length = len(password)\n",
    "        lowercase_ratio = sum(1 for c in password if c.islower()) / length\n",
    "        uppercase_ratio = sum(1 for c in password if c.isupper()) / length\n",
    "        digit_ratio = sum(1 for c in password if c.isdigit()) / length\n",
    "        symbol_ratio = sum(1 for c in password if not c.isalnum()) / length\n",
    "        features.append([entropy_val, length, lowercase_ratio, uppercase_ratio, digit_ratio, symbol_ratio])\n",
    "\n",
    "    return csr_matrix(features)  # Return as sparse matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853c89b2-c817-487e-8d4f-293d4915561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe, fmin, Trials\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import make_scorer\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "import time\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Custom Metric Function\n",
    "def custom_metric_with_wordlist(estimator, X_test, wordlist, w1=1.0, w2=1.0, w3=1.0):\n",
    "    start_time = time.time()\n",
    "    y_pred = estimator.predict(testingData)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Prediction speed (samples per second)\n",
    "    prediction_speed = len(X_test) / (end_time - start_time)\n",
    "\n",
    "    # True Positives (TP): Predicted as 1 and in the wordlist\n",
    "    true_positives = sum((password in wordlist) and (pred == 1) for password, pred in zip(X_test.ravel(), y_pred))\n",
    "    # True Negatives (TN): Predicted as 0 and not in the wordlist\n",
    "    true_negatives = sum((password not in wordlist) and (pred == 0) for password, pred in zip(X_test.ravel(), y_pred))\n",
    "    # False Positives (FP): Predicted as 1 and not in the wordlist\n",
    "    false_positives = sum((password not in wordlist) and (pred == 1) for password, pred in zip(X_test.ravel(), y_pred))\n",
    "    # False Negatives (FN): Predicted as 0 and in the wordlist\n",
    "    false_negatives = sum((password in wordlist) and (pred == 0) for password, pred in zip(X_test.ravel(), y_pred))\n",
    "\n",
    "    # Ratios\n",
    "    num_pred_0 = sum(y_pred == 0)\n",
    "    num_pred_1 = sum(y_pred == 1)\n",
    "    ratio_pred_1_0 = num_pred_1 / num_pred_0 if num_pred_0 > 0 else 0\n",
    "    false_positive_rate = false_positives / true_positives if true_positives > 0 else 0\n",
    "    if ratio_pred_1_0 == 0:\n",
    "        fistValue = 0\n",
    "    else:\n",
    "        fistValue = 1/(w1 * ratio_pred_1_0)\n",
    "    if false_positive_rate == 0:\n",
    "        secondValue = 0\n",
    "    else:\n",
    "        secondValue = 1/(w2 * false_positive_rate)\n",
    "    if prediction_speed == 0:\n",
    "        thirdValue = 0\n",
    "    else:\n",
    "        thirdValue = w3 * (1 / prediction_speed)\n",
    "    \n",
    "    score =  fistValue + secondValue + thirdValue\n",
    "    return score  # Negative for minimization\n",
    "\n",
    "# Compute custom features\n",
    "\n",
    "# Define the objective function\n",
    "def objective(params):\n",
    "    hashing_vectorizer = HashingVectorizer(\n",
    "        analyzer='char',\n",
    "        ngram_range=(1, int(params['ngram_range']))\n",
    "    )\n",
    "    logistic_regression = LogisticRegression(\n",
    "        C=params['C'], solver='saga', max_iter=5000,random_state=42\n",
    "    )\n",
    "\n",
    "    # Combine vectorizer and custom features\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('hashing', hashing_vectorizer, 0),\n",
    "            ('custom_features', FunctionTransformer(compute_dense_features, validate=False), 0)\n",
    "        ],\n",
    "        sparse_threshold=1.0\n",
    "    )\n",
    "\n",
    "    # Define the pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', logistic_regression)\n",
    "    ])\n",
    "\n",
    "    # Split data\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    pipeline.fit(trainingPass, labels)\n",
    "\n",
    "    # Evaluate using custom metric\n",
    "    score = custom_metric_with_wordlist(pipeline, testingData, wordlist, w1=1.0, w2=1.0, w3=1.0)\n",
    "    return score\n",
    "\n",
    "# Search space for Hyperopt\n",
    "space = {\n",
    "    'ngram_range': hp.quniform('ngram_range', 1, 3, 1),  # n-gram range\n",
    "    'C': hp.loguniform('C', -4, 2)  # Regularization parameter\n",
    "}\n",
    "\n",
    "# Example training data\n",
    "\n",
    "\n",
    "# Run optimization\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=15, trials=trials)\n",
    "\n",
    "print(\"Best hyperparameters:\", best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7cd1779-65a3-4388-8364-a1423df8a873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11998811-2c84-4b3e-9336-08c122f5c247",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load passwords that are longer than 8 characters, because most of the time nowadays you can't make a password that is shorter than 8 characters\n",
    "counter = 0\n",
    "trainingPass = set()\n",
    "\n",
    "\n",
    "with open(r\"C:\\Users\\1\\Downloads\\rockyou.txt\", 'r', encoding='latin1') as file:\n",
    "    for line in file:\n",
    "        counter +=1\n",
    "        stripped_line = line.strip()\n",
    "        if len(trainingPass) > 399999:\n",
    "            break\n",
    "        if len(stripped_line) > 7 and counter > 1740247:\n",
    "            trainingPass.add(stripped_line)\n",
    "            counter += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50e95c7-1b7e-44c5-9e19-4804348cdb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"generatedPasswordsTestingBigModel.txt\", \"w\",encoding=\"utf-8\") as file:\n",
    "    for index in testingData:\n",
    "        # Ensure each entry is a string\n",
    "        file.write(str(index) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df942ff8-d4b9-44c8-bc89-e06c31060163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainingPass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6345e45f-2a1a-4c1b-b3a1-f0ea57f18911",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingPass = set(trainingPass)\n",
    "len(trainingPass)\n",
    "labels = []\n",
    "for i in range(len(trainingPass)):\n",
    "    labels.append(1)\n",
    "while len(trainingPass) < 800001:\n",
    "    trainingPass.add(generate_markov_password())\n",
    "for i in range(400001):\n",
    "    labels.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf017f58-6219-4355-846c-5e1fe073fd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800001\n",
      "800001\n"
     ]
    }
   ],
   "source": [
    "print(len(trainingPass))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fec2ce96-c2f6-4f98-9e88-859c9ff360d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"PasswordsUsedForTrainingBigModel.txt\", \"w\",encoding=\"utf-8\") as file:\n",
    "    for index in trainingPass:\n",
    "        # Ensure each entry is a string\n",
    "        file.write(str(index) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d07781a1-ca6c-459e-8247-60464e42b3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained with the best hyperparameters and saved as 'password_classifier_best.pkl'.\n"
     ]
    }
   ],
   "source": [
    "trainingPass = list(trainingPass)\n",
    "best_params = {\n",
    "    'C': 3.5888871293577402,\n",
    "    'ngram_range': 2  # Convert to int if Hyperopt returned it as float\n",
    "}\n",
    "\n",
    "# HashingVectorizer with the best n-gram range\n",
    "hashing_vectorizer = HashingVectorizer(\n",
    "    analyzer='char',\n",
    "    ngram_range=(1, int(best_params['ngram_range']))\n",
    ")\n",
    "\n",
    "# Logistic Regression with the best regularization parameter\n",
    "logistic_regression = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver='saga',\n",
    "    max_iter=5000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Combine HashingVectorizer and custom feature transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('hashing', hashing_vectorizer, 0),\n",
    "        ('custom_features', FunctionTransformer(compute_dense_features, validate=False), 0)\n",
    "    ],\n",
    "    sparse_threshold=1.0\n",
    ")\n",
    "\n",
    "# Define the final pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', logistic_regression)\n",
    "])\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "pipeline.fit(np.array(trainingPass).reshape(-1,1), labels)\n",
    "\n",
    "# Save the trained model using pickle\n",
    "with open(\"better_trained.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(pipeline, model_file)\n",
    "\n",
    "print(\"Model trained with the best hyperparameters and saved as 'password_classifier_best.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981cfe1d-bce2-46d4-9e67-81c3ce2b8db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedPasse = pipeline.predict(testingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d8a362-2bd7-4e1e-aef3-00f730354246",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = []\n",
    "zeros = []\n",
    "for i in range(len(predictedPasse[i])):\n",
    "    if predictedPasse[i] == 1:\n",
    "        ones.append(testModel[i])\n",
    "    else:\n",
    "        zerros.appendnd(testModel[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e4e0d64-e421-4653-9b9c-10a76e328c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Predicted1.txt\", \"w\",encoding=\"utf-8\") as file:\n",
    "    for index in ones:\n",
    "        # Ensure each entry is a string\n",
    "        file.write(str(index) + \"\\n\")\n",
    "with open(\"Predicted0.txt\", \"w\",encoding=\"utf-8\") as file:\n",
    "    for index in zeros:\n",
    "        # Ensure each entry is a string\n",
    "        file.write(str(index) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b2e232c6-7bf3-4905-b405-b76c1644f3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50604"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ones)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
